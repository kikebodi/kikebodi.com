<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />

  <title>LLM Engineering | Running local LLMs and APIs</title>

  <!-- Bootstrap + Clean Blog -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet" />
  <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet" />
  <link href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" />
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,600,700,800" rel="stylesheet" />
  <link href="css/clean-blog.min.css" rel="stylesheet" />

  <!-- PrismJS (Okaidia dark theme) -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1/themes/prism-okaidia.min.css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1/plugins/line-numbers/prism-line-numbers.css" />

  <style>
    /* Force code blocks to look great and dark */
    pre[class*="language-"],
    code[class*="language-"] {
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      font-size: 0.95rem;
    }
    pre[class*="language-"] {
      border-radius: 10px;
      box-shadow: 0 8px 24px rgba(0, 0, 0, 0.35);
      overflow: auto;
      position: relative;
      padding-top: 3rem; /* space for copy button/header */
    }
    /* Code header (filename / label) */
    .code-header {
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      height: 2.5rem;
      display: flex;
      align-items: center;
      justify-content: space-between;
      padding: 0 0.75rem;
      color: #eaeaea;
      background: rgba(0, 0, 0, 0.5);
      border-top-left-radius: 10px;
      border-top-right-radius: 10px;
      font-size: 0.85rem;
      letter-spacing: 0.2px;
    }
    .copy-btn {
      border: 1px solid rgba(255, 255, 255, 0.25);
      background: rgba(255, 255, 255, 0.08);
      color: #fff;
      border-radius: 6px;
      padding: 0.25rem 0.5rem;
      cursor: pointer;
      transition: background 0.2s ease, border 0.2s ease;
    }
    .copy-btn:hover {
      background: rgba(255, 255, 255, 0.18);
      border-color: rgba(255, 255, 255, 0.45);
    }
    /* Improve table contrast on dark */
    @media (prefers-color-scheme: dark) {
      body {
        color: #eaeaea;
        background-color: #0f1115;
      }
      .navbar-light .navbar-brand,
      .navbar-light .navbar-nav .nav-link {
        color: #eaeaea !important;
      }
      .table {
        color: #eaeaea;
      }
      .table-bordered td,
      .table-bordered th {
        border-color: #2a2f3a;
      }
      .copyright {
        color: #9aa1aa !important;
      }
    }
    /* Masthead image tint for readability */
    .masthead .overlay {
      background-color: rgba(0, 0, 0, 0.45);
    }
  </style>
</head>

<body>
  <!-- Navbar -->
  <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
    <div class="container">
      <a class="navbar-brand" href="index.html">Kike Bodi</a>
      <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        Menu
        <i class="fas fa-bars"></i>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link" href="index.html">Home</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="about.html">About</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="portfolio.html">Portfolio</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="contact.html">Contact</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <!-- Header -->
  <header class="masthead" style="background-image: url('img/synthetic-retro-wave.jpg')">
    <div class="overlay"></div>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
          <div class="post-heading">
            <h1>LLM Engineering | Running local LLMs and APIs</h1>
            <h2 class="subheading">LLM Engineering Course notes and code snippets</h2>
            <span class="meta">Posted by <a href="#">Kike Bod√≠</a> on November 2025</span>
          </div>
        </div>
      </div>
    </div>
  </header>

  <!-- Content -->
  <article>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
          <p>Here are some notes and code snippets extracted from the LLM Engineering Course. Will expand in the future.</p>

          <h2 class="section-heading">1Ô∏è‚É£ Run Local Models with Ollama</h2>

          <pre id="code-ollama-bash" class="line-numbers">
            <code class="language-bash"># Install Ollama
            curl -fsSL https://ollama.com/install.sh | sh
            
            # Pull Llama 3.2 (small)
            ollama pull llama3.2
            
            # Chat from CLI
            ollama run llama3.2</code>
          </pre>

          <pre id="code-ollama-py" class="line-numbers">
            <code class="language-python">import ollama
          
            resp = ollama.chat(
              model="llama3.2",
              messages=[{"role": "user", "content": "Explain transformers in 2 sentences"}]
            )
            print(resp.choices[0].message.content)</code>
          </pre>

          <h2 class="section-heading">2Ô∏è‚É£ OpenAI API</h2>

          <pre id="code-openai" class="line-numbers">
            <code class="language-python">from openai import OpenAI
            import os

            # set OPENAI_API_KEY in your environment or .env
            client = OpenAI()

            resp = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "Summarize the transformer architecture."}
                ]
            )
            print(resp.choices[0].message.content)</code></pre>

            <p><em>Note:</em> We can also stream Open AI answer by adding <code>stream=True</code> to the object.</p>


          <h2 class="section-heading">3Ô∏è‚É£ Anthropic API (Stream)</h2>

          <pre id="code-anthropic" class="line-numbers">
            <code class="language-python">import anthropic

            claude = anthropic.Anthropic()
            resp = claude.messages.create(
                model="claude-3-haiku-20240307",
                max_tokens=200,
                temperature=0.7,
                system = "You are a teacher",
                messages=[{"role": "user", "content": "Explain how LLMs work"}],
            )
            response = ""
            with result as stream:
              for text in stream.text_stream:
                  response += text or ""
                  yield response
                </code></pre>

          <h2 class="section-heading">üí¨ Update:</h2>
          <p>We will build on top of these APIs, enabling tools, adding context and creating Agents in LangChain.</p>

          <h2 class="section-heading">4Ô∏è‚É£ OpenRouter API</h2>

          <p>
          We can use OpenRouter to use different models provided by an unified API. Several models are available: OpenAI, Anthropic, Google, Mistral, DeepSeek and many others.  
          </p>
          
          <pre id="code-openrouter" class="line-numbers">
            <code class="language-python">import OpenAI

            message = [{"role": "user", "content": "Explain how LLMs work"},]
            openrouter = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=openrouter_api_key)

            response = openrouter.chat.completions.create(model="kwaipilot/kat-coder-pro:free", messages=message)
            display(response.choices[0].message.content)</code>
          </pre>
          <h2 class="section-heading">5Ô∏è‚É£ LangChain</h2>

          <p>
          LangChain helps you build agents, tools, retrieval pipelines and chain sequences with minimal boilerplate.  
          Very useful when you want multi-step reasoning or tool usage.
          </p>
          
          <pre id="code-langchain-basic" class="line-numbers">
            <div class="code-header"><span>langchain_basic.py</span></div>
            <code class="language-python">from langchain_openai import ChatOpenAI
            
            message = [{"role": "user", "content": "Explain how LLMs work"},]
            llm = ChatOpenAI(model="gpt-5-mini")

            response = llm.invoke(message)
            
            display(Markdown(response.content))</code>
          </pre><br>
          <h3>üîß Example: Agent with a Python Tool</h3>

          <pre id="code-langchain-tool" class="line-numbers">
            <code class="language-python">from langchain.agents import initialize_agent, Tool
            from langchain.chat_models import ChatOpenAI
            
            def get_temperature(city: str):
                return f"The temperature in {city} is 20¬∫C."
            
            tools = [
                Tool(
                    name="weather",
                    func=get_temperature,
                    description="Return temperature of a city."
                )
            ]
            
            llm = ChatOpenAI(model="gpt-4o")
            
            agent = initialize_agent(
                tools=tools,
                llm=llm,
                agent="zero-shot-react-description"
            )
            
            print(agent.run("What's the temperature in Copenhagen?"))</code>
          </pre>
          
          <p><strong>Great for:</strong> multi-step reasoning, tool-enabled assistants, and structured agents.</p>

          <h2 class="section-heading">6Ô∏è‚É£ LiteLLM</h2>

          <p>
          LiteLLM is a unified Python client for 100+ LLM providers (OpenAI, Anthropic, Groq, OpenRouter, Azure‚Ä¶).  
          You use <code>completion()</code> or <code>chat.completion()</code> and change only the model string.
          </p>
          
          <pre id="code-litellm-basic" class="line-numbers">
            <code class="language-python">from litellm import completion

            message = [{"role": "user", "content": "Explain how LLMs work"},]

            response = completion(model="openai/gpt-4.1", messages=message)
            reply = response.choices[0].message.content
            display(Markdown(reply))</code>
          </pre>

          <p><em>Note:</em> We can also get extra information on tokens and costs.

          <pre id="code-litellm-basic" class="line-numbers">
          <code class="language-python">print(f"Input tokens: {response.usage.prompt_tokens}")
          print(f"Output tokens: {response.usage.completion_tokens}")
          print(f"Total tokens: {response.usage.total_tokens}")
          print(f"Total cost: {response._hidden_params["response_cost"]*100:.4f} cents")</code>
        </pre>

        </div>
      </div>
    </div>
  </article>

  <hr />

  <!-- Footer -->
  <footer>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
          <ul class="list-inline text-center">
            <li class="list-inline-item">
              <a href="https://www.linkedin.com/in/kikebodi/" target="_blank">
                <span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i><i
                    class="fab fa-linkedin-in fa-stack-1x fa-inverse"></i></span>
              </a>
            </li>
            <li class="list-inline-item">
              <a href="https://github.com/kikebodi" target="_blank">
                <span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i><i
                    class="fab fa-github fa-stack-1x fa-inverse"></i></span>
              </a>
            </li>
          </ul>
          <p class="copyright text-muted">¬© Kike Bod√≠ 2025</p>
        </div>
      </div>
    </div>
  </footer>

  <!-- JS -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="js/clean-blog.min.js"></script>

  <!-- PrismJS core + languages + plugins -->
  <script src="https://cdn.jsdelivr.net/npm/prismjs@1/components/prism-core.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/prismjs@1/plugins/autoloader/prism-autoloader.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/prismjs@1/plugins/line-numbers/prism-line-numbers.min.js"></script>
</body>
</html>
