<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />

  <title>Building a Private RAG System with Ollama, LangChain and Chroma - LLM Engineer | AI Agent Engineer | Senior Software Developer</title>

    <!-- Open Graph -->
<meta property="og:type" content="article" />
<meta property="og:title" content="Building a Private RAG System with LangChain, Chroma, and Local LLMs" />
<meta property="og:description" content="End-to-end guide to building a private Retrieval-Augmented Generation (RAG) system using LangChain, Chroma, and local/open-source LLMs. Includes embeddings, chunking, vector search, and evaluation." />
<meta property="og:url" content="https://kikebodi.com/private-rag-vector-database.html" />
<meta property="og:image" content="https://kikebodi.com/img/rag_diagram.png" />
<meta property="og:site_name" content="Kike Bodi — LLM Engineering & AI Systems" />

<!-- Twitter / X -->
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:title" content="Private RAG with LangChain, Chroma, and Local LLMs" />
<meta name="twitter:description" content="Hands-on RAG tutorial: private vector database with Chroma, LangChain retriever pipeline, and local LLMs for enterprise-ready AI search." />
<meta name="twitter:image" content="https://kikebodi.com/img/rag_diagram.png" />

  <!-- Bootstrap + Clean Blog -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet" />
  <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet" />
  <link href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" />
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,600,700,800" rel="stylesheet" />
  <link href="css/clean-blog.min.css" rel="stylesheet" />

  <!-- PrismJS (Okaidia dark theme) -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1/themes/prism-okaidia.min.css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1/plugins/line-numbers/prism-line-numbers.css" />

  <style>
    /* Force code blocks to look great and dark */
    pre[class*="language-"],
    code[class*="language-"] {
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      font-size: 0.95rem;
    }
    pre[class*="language-"] {
      border-radius: 10px;
      box-shadow: 0 8px 24px rgba(0, 0, 0, 0.35);
      overflow: auto;
      position: relative;
      padding-top: 3rem; /* space for copy button/header */
    }
    /* Code header (filename / label) */
    .code-header {
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      height: 2.5rem;
      display: flex;
      align-items: center;
      justify-content: space-between;
      padding: 0 0.75rem;
      color: #eaeaea;
      background: rgba(0, 0, 0, 0.5);
      border-top-left-radius: 10px;
      border-top-right-radius: 10px;
      font-size: 0.85rem;
      letter-spacing: 0.2px;
    }
    .copy-btn {
      border: 1px solid rgba(255, 255, 255, 0.25);
      background: rgba(255, 255, 255, 0.08);
      color: #fff;
      border-radius: 6px;
      padding: 0.25rem 0.5rem;
      cursor: pointer;
      transition: background 0.2s ease, border 0.2s ease;
    }
    .copy-btn:hover {
      background: rgba(255, 255, 255, 0.18);
      border-color: rgba(255, 255, 255, 0.45);
    }
    /* Improve table contrast on dark */
    @media (prefers-color-scheme: dark) {
      body {
        color: #eaeaea;
        background-color: #0f1115;
      }
      .navbar-light .navbar-brand,
      .navbar-light .navbar-nav .nav-link {
        color: #eaeaea !important;
      }
      .table {
        color: #eaeaea;
      }
      .table-bordered td,
      .table-bordered th {
        border-color: #2a2f3a;
      }
      .copyright {
        color: #9aa1aa !important;
      }
    }
    /* Masthead image tint for readability */
    .masthead .overlay {
      background-color: rgba(0, 0, 0, 0.45);
    }
  </style>
  <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "TechArticle",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://kikebodi.com/private-rag-vector-database.html"
  },
  "headline": "Building a Private RAG System with LangChain, Chroma, and Local LLMs",
  "description": "A practical, end-to-end guide to building a private Retrieval-Augmented Generation (RAG) system using LangChain, Chroma, and open-source LLMs. Covers embeddings, chunking, vector search, pipelines, and productionization.",
  "keywords": [
    "RAG",
    "Retrieval-Augmented Generation",
    "Vector Databases",
    "Chroma",
    "LangChain",
    "Embeddings",
    "LLM Engineering",
    "AI Agents",
    "Ollama",
    "Private LLMs",
    "Enterprise RAG",
    "Token Optimization",
    "Document Indexing",
    "AI Workflows",
    "Multi-model pipelines"
  ],
  "author": {
    "@type": "Person",
    "name": "Enrique Bodí",
    "url": "https://kikebodi.com"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Enrique Bodí — LLM Engineering & AI Systems",
    "url": "https://kikebodi.com",
    "logo": {
      "@type": "ImageObject",
      "url": "https://kikebodi.com/img/profile.jpg"
    }
  },
  "datePublished": "2025-11-23",
  "dateModified": "2025-11-23",
  "image": "https://kikebodi.com/img/rag_diagram.png",
  "articleSection": "LLM Engineering",
  "learningResourceType": "Tutorial",
  "proficiencyLevel": "Expert",
  "about": [
    {
      "@type": "Thing",
      "name": "LLM Engineering"
    },
    {
      "@type": "Thing",
      "name": "Private RAG Systems"
    },
    {
      "@type": "Thing",
      "name": "AI Infrastructure"
    },
    {
      "@type": "Thing",
      "name": "Enterprise AI Systems"
    }
  ]
}
</script>
</head>
<body>
  <!-- Navbar -->
  <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
    <div class="container">
      <a class="navbar-brand" href="index.html">Kike Bodi</a>
      <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        Menu
        <i class="fas fa-bars"></i>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link" href="index.html">Home</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="about.html">About</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="portfolio.html">Portfolio</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="contact.html">Contact</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <!-- Header -->
  <header class="masthead" style="background-image: url('img/rag-vector-database-landscape.jpg')">
  <div class="overlay"></div>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-md-10 mx-auto">
        <div class="post-heading">
          <h1>Building a Private RAG System with Ollama, LangChain and Chroma</h1>
          <h2 class="subheading">Part 4: RAG implementation</h2>
          <span class="meta">Posted by <a href="#">Kike Bodí</a> on January 2026</span>
        </div>
      </div>
    </div>
  </div>
</header>
  <article>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-md-10 mx-auto">
        <h2 class="section-heading">Series Index</h2>
        <ol>
          <li><a href="./private-rag-vector-database.html#rag-prerequisites">Prerequisites</a></li>
          <li><a href="./private-rag-vector-database.html#rag-populate-db">Populate the Vector Database</a></li>
          <li><a href="./private-rag-retriever.html#rag-retriever">Vector Retriever</a></li>
          <li>RAG implementation</li>
          <li>Chat UI</li>
          <li>Evaluation</li>
          <li>Performance improvements</li>
        </ol>

        <div id="rag-implementation">
        <h2 class="section-heading">4. RAG implementation</h2>

        <p>
          In addition to the Retriever, we will need our Auto-regresive (conversational) LLM:
        </p>

        <pre class="line-numbers"><code class="language-python">llm = ChatOpenAI(temperature=0, model_name=MODEL)</code></pre>

        <p>
        	Together with the Retriever we defined in the previous post, we have everything we need to build the RAG:
        </p>

        <pre class="line-numbers"><code class="language-python">
			SYSTEM_PROMPT_TEMPLATE = """
			You are a knowledgeable, friendly assistant representing Desert Leaves.
			You are chatting internally with a technician from Desert Leaves.
			If relevant, use the given context to answer any question.
			If you don't know the answer, say so.
			Context:
			{context}
			"""
			
			def fetch_context(question: str) -> list[Document]:
			    """
			    Retrieve relevant context documents for a question.
			    """
			    return retriever.invoke(question, k=RETRIEVAL_K)
			
			
			def combined_question(question: str, history: list[dict] = []) -> str:
			    """
			    Combine all the user's messages into a single string.
			    """
			    prior = "\n".join(m["content"] for m in history if m["role"] == "user")
			    return prior + "\n" + question
			
			
			def answer_question(question: str, history: list[dict] = []) -> tuple[str, list[Document]]:
			    """
			    Answer the given question with RAG; return the answer and the context documents.
			    """
			    combined = combined_question(question, history)
			    docs = fetch_context(combined)
			    context = "\n\n".join(doc.page_content for doc in docs)
			    system_prompt = SYSTEM_PROMPT.format(context=context)
			    messages = [SystemMessage(content=system_prompt)]
			    messages.extend(convert_to_messages(history))
			    messages.append(HumanMessage(content=question))
			    response = llm.invoke(messages)
			    return response.content, docs</code></pre>

		</div>

		<div id="rag-implementation">
        <h2 class="section-heading">5. UI with Gradio</h2>

        <pre class="line-numbers"><code class="language-python">gr.ChatInterface(answer_question).launch()</code></pre>


        <p>
        	As simple as that
        </p>

			
        <p>
          Nice work! With this short step, we’ve covered <strong>about 90%</strong>of our private RAG system.
        </p>

         <p>
          Missing something? It is probably on the previous section <a href="./private-rag-vector-database.html#rag-populate-db">
        Part 2: Populate your private vector database
      </a> 
      </div>
   <hr />
<div class="container my-4">
  <h3>More LLM Engineering articles</h3>
  <ul>
    <li>
      <a href="https://kikebodi.com/llm-engineering-token-optimization.html">
        LLM Engineering | Token optimization
      </a> – caching, thin system prompts, and cost-optimized production usage.
    </li>
    <li>
      <a href="https://kikebodi.com/llm-engineering-basic-usage.html">
        LLM Engineering | Running local LLMs and APIs
      </a> – Ollama, OpenAI, Anthropic, OpenRouter, LangChain, and LiteLLM.
    </li>
  </ul>
</div>
    </div>
    </div>
  </div>
</article>

  <!-- JS -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="js/clean-blog.min.js"></script>

  <!-- PrismJS core + languages + plugins -->
  <script src="https://cdn.jsdelivr.net/npm/prismjs@1/components/prism-core.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/prismjs@1/plugins/autoloader/prism-autoloader.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/prismjs@1/plugins/line-numbers/prism-line-numbers.min.js"></script>
</body>
</html>